sudo: false
language: python

# don't clone the whole repo history, one commit will do
git:
  depth: 1

# only build branches we care about (PRs are built seperately)
#branches:
#  only:
#    - master
#    - develop
#    - /^release-v.*/

cache:
  directories:
    # we only bother to cache the wheels; parts of the http cache get
    # invalidated every build (because they get served with a max-age of 600
    # seconds), which means that we end up re-uploading the whole cache for
    # every build, which is time-consuming. In any case, it's not obvious that
    # downloading the cache from S3 would be much faster than downloading the
    # originals from pypi.
    - $HOME/cache/pip/wheels

matrix:
  fast_finish: true
  include:
  - python: 2.7
    env:
      - TOX_ENV=py27
      - XDG_CACHE_HOME=$HOME/cache
   
install:
  - pip install tox

script:
  - find $XDG_CACHE_HOME/pip -type f -print0 | xargs -0r ls -l 
  - tox -vve $TOX_ENV
  - find $XDG_CACHE_HOME/pip -type f -print0 | xargs -0r ls -l 
